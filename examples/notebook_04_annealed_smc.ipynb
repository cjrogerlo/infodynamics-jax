{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: 貝葉斯推斷（Annealed SMC + IBIS）\n",
    "\n",
    "本 notebook 示範如何使用粒子方法進行完整的貝葉斯推斷。\n",
    "\n",
    "**學習目標：**\n",
    "- 理解 MAP-II vs 完整貝葉斯推斷\n",
    "- 學習 Annealed SMC 的工作原理\n",
    "- 學習 IBIS 用於在線/流式推斷\n",
    "- 量化超參數的不確定性\n",
    "\n",
    "**主要概念：**\n",
    "- **Annealed SMC**: 從先驗到後驗的退火過程\n",
    "- **IBIS**: 迭代批次重要性採樣，用於流式數據\n",
    "- **粒子方法**: 使用粒子雲近似後驗分布\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['JAX_PLATFORM_NAME'] = 'cpu'\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plotting_style import COLORS, PALETTES, setup_plot_style, get_figure_size, format_axes\n",
    "setup_plot_style()\n",
    "\n",
    "from infodynamics_jax.core import Phi, SupervisedData\n",
    "from infodynamics_jax.gp.kernels.params import KernelParams\n",
    "from infodynamics_jax.gp.kernels.rbf import rbf as rbf_kernel\n",
    "from infodynamics_jax.gp.likelihoods import get as get_likelihood\n",
    "from infodynamics_jax.energy import InertialEnergy, InertialCFG\n",
    "from infodynamics_jax.inference.particle import AnnealedSMC, AnnealedSMCCFG\n",
    "from infodynamics_jax.inference.optimisation import TypeII, TypeIICFG\n",
    "from infodynamics_jax.infodynamics import run, RunCFG\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "os.environ['JAX_PLATFORM_NAME'] = 'cpu'\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import COLORS, PALETTES, setup_plot_style, get_figure_size, format_axes\n",
    "setup_plot_style()\n",
    "\n",
    "from infodynamics_jax.core import Phi, SupervisedData\n",
    "from infodynamics_jax.gp.kernels.params import KernelParams\n",
    "from infodynamics_jax.gp.kernels.rbf import rbf as rbf_kernel\n",
    "from infodynamics_jax.gp.likelihoods import get as get_likelihood\n",
    "from infodynamics_jax.energy import InertialEnergy, InertialCFG\n",
    "from infodynamics_jax.inference.particle import AnnealedSMC, AnnealedSMCCFG\n",
    "from infodynamics_jax.inference.optimisation import TypeII, TypeIICFG\n",
    "from infodynamics_jax.infodynamics import run, RunCFG\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MAP-II vs 完整貝葉斯推斷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP-II (Maximum A Posteriori Type-II)\n",
    "- 尋找**單一最佳**超參數: φ* = argmax_φ p(φ | y)\n",
    "- 快速、確定性\n",
    "- 無超參數不確定性量化\n",
    "- 小數據集有過擬合風險\n",
    "\n",
    "### 完整貝葉斯 (Annealed SMC)\n",
    "- 近似**整個後驗**: p(φ | y)\n",
    "- 通過粒子雲表示不確定性\n",
    "- 對過擬合更魯棒\n",
    "- 計算成本: O(P × T) 其中 P = 粒子數，T = 退火步數\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 生成數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(789)\n",
    "\n",
    "# 小數據集以觀察不確定性\n",
    "N_train = 30\n",
    "X_train = jnp.linspace(-4, 4, N_train)[:, None]\n",
    "\n",
    "# 真實函數\n",
    "def true_function(x):\n",
    "    return jnp.sin(2 * x[:, 0]) + 0.3 * x[:, 0]\n",
    "\n",
    "f_train = true_function(X_train)\n",
    "\n",
    "# 添加噪聲\n",
    "key, subkey = jax.random.split(key)\n",
    "noise_std = 0.3\n",
    "Y_train = f_train + noise_std * jax.random.normal(subkey, (N_train,))\n",
    "\n",
    "# 測試集\n",
    "X_test = jnp.linspace(-5, 5, 100)[:, None]\n",
    "f_test = true_function(X_test)\n",
    "\n",
    "print(f\"訓練集: {N_train} 個點\")\n",
    "print(f\"真實噪聲標準差: {noise_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 基線：MAP-II 優化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "kernel_params = KernelParams(lengthscale=jnp.array(1.0), variance=jnp.array(1.0))\n",
    "M = 10\n",
    "Z = jnp.linspace(X_train.min(), X_train.max(), M)[:, None]\n",
    "\n",
    "phi_init = Phi(\n",
    "    kernel_params=kernel_params,\n",
    "    Z=Z,\n",
    "    likelihood_params={\"noise_var\": jnp.array(0.1)},\n",
    "    jitter=1e-5,\n",
    ")\n",
    "\n",
    "# 能量\n",
    "gaussian_likelihood = get_likelihood(\"gaussian\")\n",
    "inertial_cfg = InertialCFG(estimator=\"gh\", gh_n=20, inner_steps=0)\n",
    "inertial_energy = InertialEnergy(\n",
    "    kernel_fn=rbf_kernel,\n",
    "    likelihood=gaussian_likelihood,\n",
    "    cfg=inertial_cfg,\n",
    ")\n",
    "\n",
    "# 運行 MAP-II\n",
    "from infodynamics_jax.inference.optimisation.vfe import make_vfe_objective\n",
    "vfe_objective = make_vfe_objective(kernel_fn=rbf_kernel, residual=\"fitc\")\n",
    "typeii_cfg = TypeIICFG(steps=100, lr=1e-2, optimizer=\"adam\", jit=True, constrain_params=True)\n",
    "method = TypeII(cfg=typeii_cfg)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "result_map = method.run(\n",
    "    energy=vfe_objective,\n",
    "    phi_init=phi_init,\n",
    "    energy_args=(X_train, Y_train),\n",
    ")\n",
    "\n",
    "phi_map = result_map.phi\n",
    "\n",
    "print(\"MAP-II 結果:\")\n",
    "print(f\"  長度尺度: {float(phi_map.kernel_params.lengthscale):.3f}\")\n",
    "print(f\"  方差: {float(phi_map.kernel_params.variance):.3f}\")\n",
    "print(f\"  噪聲方差: {float(phi_map.likelihood_params['noise_var']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 運行 Annealed SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_particles_fn(key, n_particles: int):\n",
    "    \"\"\"從先驗初始化粒子\"\"\"\n",
    "    keys = jax.random.split(key, n_particles)\n",
    "    \n",
    "    def init_one(key_i):\n",
    "        key_l, key_v, key_z, key_n = jax.random.split(key_i, 4)\n",
    "        \n",
    "        # 長度尺度: 對數正態分佈\n",
    "        lengthscale = jnp.exp(jax.random.normal(key_l, ()) * 0.5)\n",
    "        \n",
    "        # 方差: 對數正態分佈\n",
    "        variance = jnp.exp(jax.random.normal(key_v, ()) * 0.5)\n",
    "        \n",
    "        # 誘導點: 輕微擾動\n",
    "        Z_noisy = phi_init.Z + jax.random.normal(key_z, phi_init.Z.shape) * 0.2\n",
    "        \n",
    "        # 噪聲方差: 對數正態分佈\n",
    "        noise_var = jnp.exp(jnp.log(0.1) + jax.random.normal(key_n, ()) * 0.5)\n",
    "        \n",
    "        # 約束為正值\n",
    "        lengthscale = jnp.maximum(lengthscale, 0.1)\n",
    "        variance = jnp.maximum(variance, 0.1)\n",
    "        noise_var = jnp.maximum(noise_var, 0.01)\n",
    "        \n",
    "        return Phi(\n",
    "            kernel_params=KernelParams(lengthscale=lengthscale, variance=variance),\n",
    "            Z=Z_noisy,\n",
    "            likelihood_params={\"noise_var\": noise_var},\n",
    "            jitter=phi_init.jitter,\n",
    "        )\n",
    "    \n",
    "    return jax.vmap(init_one)(keys)\n",
    "\n",
    "print(\"粒子初始化函數已創建！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置 Annealed SMC\n",
    "smc_cfg = AnnealedSMCCFG(\n",
    "    n_particles=64,           # 粒子數\n",
    "    n_steps=20,               # 退火步數\n",
    "    ess_threshold=0.5,        # 當 ESS < 0.5 * n_particles 時重採樣\n",
    "    rejuvenation=\"hmc\",       # 使用 HMC 進行粒子更新\n",
    "    rejuvenation_steps=2,     # 每次更新的 HMC 步數\n",
    "    jit=True,                 # 啟用 JIT\n",
    ")\n",
    "\n",
    "method_smc = AnnealedSMC(cfg=smc_cfg)\n",
    "\n",
    "print(f\"Annealed SMC 配置:\")\n",
    "print(f\"  粒子數: {smc_cfg.n_particles}\")\n",
    "print(f\"  退火步數: {smc_cfg.n_steps}\")\n",
    "print(f\"  更新方法: {smc_cfg.rejuvenation} ({smc_cfg.rejuvenation_steps} 步)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 運行 Annealed SMC\n",
    "print(\"運行 Annealed SMC...\")\n",
    "print(\"這可能需要一分鐘...\")\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "result_smc = method_smc.run(\n",
    "    energy=inertial_energy,\n",
    "    init_particles_fn=init_particles_fn,\n",
    "    key=subkey,\n",
    "    energy_args=(X_train, Y_train),\n",
    ")\n",
    "\n",
    "particles = result_smc.particles\n",
    "logw = result_smc.logw\n",
    "ess_trace = result_smc.ess_trace\n",
    "\n",
    "print(\"\\nAnnealed SMC 結果:\")\n",
    "print(f\"  最終 ESS: {ess_trace[-1]:.1f} / {smc_cfg.n_particles}\")\n",
    "print(f\"  對數權重範圍: [{logw.min():.2f}, {logw.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 分析後驗分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取粒子值\n",
    "lengthscales = np.array(particles.kernel_params.lengthscale)\n",
    "variances = np.array(particles.kernel_params.variance)\n",
    "noise_vars = np.array(particles.likelihood_params[\"noise_var\"])\n",
    "\n",
    "# 歸一化權重\n",
    "weights = np.exp(logw - logw.max())\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# 加權統計\n",
    "lengthscale_mean = float(np.sum(weights * lengthscales))\n",
    "lengthscale_std = float(np.sqrt(np.sum(weights * (lengthscales - lengthscale_mean)**2)))\n",
    "\n",
    "variance_mean = float(np.sum(weights * variances))\n",
    "variance_std = float(np.sqrt(np.sum(weights * (variances - variance_mean)**2)))\n",
    "\n",
    "noise_var_mean = float(np.sum(weights * noise_vars))\n",
    "noise_var_std = float(np.sqrt(np.sum(weights * (noise_vars - noise_var_mean)**2)))\n",
    "\n",
    "print(\"後驗統計（加權）:\")\n",
    "print(f\"\\n長度尺度:\")\n",
    "print(f\"  均值: {lengthscale_mean:.3f} ± {lengthscale_std:.3f}\")\n",
    "print(f\"  MAP:  {float(phi_map.kernel_params.lengthscale):.3f}\")\n",
    "\n",
    "print(f\"\\n方差:\")\n",
    "print(f\"  均值: {variance_mean:.3f} ± {variance_std:.3f}\")\n",
    "print(f\"  MAP:  {float(phi_map.kernel_params.variance):.3f}\")\n",
    "\n",
    "print(f\"\\n噪聲方差:\")\n",
    "print(f\"  均值: {noise_var_mean:.3f} ± {noise_var_std:.3f}\")\n",
    "print(f\"  MAP:  {float(phi_map.likelihood_params['noise_var']):.3f}\")\n",
    "print(f\"  真實: {noise_std**2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化後驗分布和結果\n",
    "from infodynamics_jax.gp.predict import predict_typeii\n",
    "\n",
    "# 1. 繪製後驗分布直方圖\n",
    "fig, axes = plt.subplots(2, 2, figsize=get_figure_size('wide', 1.0))\n",
    "\n",
    "# ESS 軌跡\n",
    "ax = axes[0, 0]\n",
    "ax.plot(ess_trace, lw=2, color=COLORS['primary'])\n",
    "ax.axhline(smc_cfg.ess_threshold * smc_cfg.n_particles, ls='--', \n",
    "          color=COLORS['accent'], label=f'ESS 閾值 ({smc_cfg.ess_threshold * smc_cfg.n_particles:.0f})')\n",
    "format_axes(ax, title='有效樣本大小 (ESS) 軌跡', xlabel='退火步數', ylabel='ESS', legend=True)\n",
    "\n",
    "# 長度尺度後驗分布\n",
    "ax = axes[0, 1]\n",
    "ax.hist(lengthscales, weights=weights, bins=30, alpha=0.7, \n",
    "       color=COLORS['primary'], edgecolor='black', density=True)\n",
    "ax.axvline(lengthscale_mean, ls='--', lw=2, color=COLORS['accent'], \n",
    "          label=f'均值: {lengthscale_mean:.3f}')\n",
    "ax.axvline(float(phi_map.kernel_params.lengthscale), ls=':', lw=2, \n",
    "          color=COLORS['secondary'], label=f'MAP: {float(phi_map.kernel_params.lengthscale):.3f}')\n",
    "format_axes(ax, title='長度尺度後驗分布', xlabel='長度尺度', ylabel='密度', legend=True)\n",
    "\n",
    "# 方差後驗分布\n",
    "ax = axes[1, 0]\n",
    "ax.hist(variances, weights=weights, bins=30, alpha=0.7, \n",
    "       color=COLORS['secondary'], edgecolor='black', density=True)\n",
    "ax.axvline(variance_mean, ls='--', lw=2, color=COLORS['accent'], \n",
    "          label=f'均值: {variance_mean:.3f}')\n",
    "ax.axvline(float(phi_map.kernel_params.variance), ls=':', lw=2, \n",
    "          color=COLORS['primary'], label=f'MAP: {float(phi_map.kernel_params.variance):.3f}')\n",
    "format_axes(ax, title='方差後驗分布', xlabel='方差', ylabel='密度', legend=True)\n",
    "\n",
    "# 噪聲方差後驗分布\n",
    "ax = axes[1, 1]\n",
    "ax.hist(noise_vars, weights=weights, bins=30, alpha=0.7, \n",
    "       color=COLORS['tertiary'], edgecolor='black', density=True)\n",
    "ax.axvline(noise_var_mean, ls='--', lw=2, color=COLORS['accent'], \n",
    "          label=f'均值: {noise_var_mean:.3f}')\n",
    "ax.axvline(float(phi_map.likelihood_params['noise_var']), ls=':', lw=2, \n",
    "          color=COLORS['primary'], label=f'MAP: {float(phi_map.likelihood_params[\"noise_var\"]):.3f}')\n",
    "ax.axvline(noise_std**2, ls='-', lw=2, color='red', alpha=0.7, \n",
    "          label=f'真實: {noise_std**2:.3f}')\n",
    "format_axes(ax, title='噪聲方差後驗分布', xlabel='噪聲方差', ylabel='密度', legend=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. 使用加權粒子進行預測（貝葉斯模型平均）\n",
    "print(\"\\n計算加權預測（貝葉斯模型平均）...\")\n",
    "\n",
    "# 對每個粒子進行預測，然後加權平均\n",
    "def predict_with_particle(phi_particle):\n",
    "    mu, var = predict_typeii(\n",
    "        phi_particle,\n",
    "        X_test,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        kernel_fn=rbf_kernel,\n",
    "        residual=\"fitc\",\n",
    "    )\n",
    "    return mu, var\n",
    "\n",
    "# 向量化預測\n",
    "n_particles = len(particles.kernel_params.lengthscale)\n",
    "mu_predictions = []\n",
    "var_predictions = []\n",
    "\n",
    "# 獲取 jitter（可能是標量或數組）\n",
    "if hasattr(particles, 'jitter'):\n",
    "    if isinstance(particles.jitter, (int, float)):\n",
    "        jitter_val = particles.jitter\n",
    "    else:\n",
    "        jitter_val = particles.jitter[0] if len(particles.jitter) > 0 else 1e-5\n",
    "else:\n",
    "    jitter_val = 1e-5\n",
    "\n",
    "for i in range(n_particles):\n",
    "    phi_i = Phi(\n",
    "        kernel_params=KernelParams(\n",
    "            lengthscale=particles.kernel_params.lengthscale[i],\n",
    "            variance=particles.kernel_params.variance[i]\n",
    "        ),\n",
    "        Z=particles.Z[i],\n",
    "        likelihood_params={\"noise_var\": particles.likelihood_params[\"noise_var\"][i]},\n",
    "        jitter=jitter_val,\n",
    "    )\n",
    "    mu_i, var_i = predict_with_particle(phi_i)\n",
    "    mu_predictions.append(mu_i)\n",
    "    var_predictions.append(var_i)\n",
    "\n",
    "mu_predictions = jnp.array(mu_predictions)  # (n_particles, N_test)\n",
    "var_predictions = jnp.array(var_predictions)  # (n_particles, N_test)\n",
    "\n",
    "# 加權平均\n",
    "weights_array = jnp.array(weights)\n",
    "mu_weighted = jnp.sum(weights_array[:, None] * mu_predictions, axis=0)\n",
    "# 對於方差，使用 E[var] + Var[mean] 公式\n",
    "var_weighted = jnp.sum(weights_array[:, None] * var_predictions, axis=0) + \\\n",
    "               jnp.sum(weights_array[:, None] * (mu_predictions - mu_weighted[None, :])**2, axis=0)\n",
    "\n",
    "# 3. 繪製預測結果\n",
    "fig, ax = plt.subplots(1, 1, figsize=get_figure_size('wide', 0.6))\n",
    "\n",
    "# 測試集真實函數\n",
    "ax.plot(X_test[:, 0], f_test, 'k-', lw=2, label='真實函數', alpha=0.7)\n",
    "\n",
    "# 訓練數據\n",
    "ax.scatter(X_train[:, 0], Y_train, s=50, c=COLORS['primary'], \n",
    "          alpha=0.6, edgecolors='black', label='訓練數據', zorder=5)\n",
    "\n",
    "# MAP 預測\n",
    "mu_map, var_map = predict_typeii(\n",
    "    phi_map,\n",
    "    X_test,\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    kernel_fn=rbf_kernel,\n",
    "    residual=\"fitc\",\n",
    ")\n",
    "std_map = jnp.sqrt(var_map)\n",
    "ax.plot(X_test[:, 0], mu_map, '--', lw=2, color=COLORS['secondary'], \n",
    "       label='MAP 預測', alpha=0.8)\n",
    "ax.fill_between(X_test[:, 0], mu_map - 2*std_map, mu_map + 2*std_map, \n",
    "               alpha=0.2, color=COLORS['secondary'])\n",
    "\n",
    "# 加權貝葉斯預測\n",
    "std_weighted = jnp.sqrt(var_weighted)\n",
    "ax.plot(X_test[:, 0], mu_weighted, '-', lw=2, color=COLORS['accent'], \n",
    "       label='貝葉斯平均預測', alpha=0.9)\n",
    "ax.fill_between(X_test[:, 0], mu_weighted - 2*std_weighted, mu_weighted + 2*std_weighted, \n",
    "               alpha=0.3, color=COLORS['accent'], label='±2σ 不確定性')\n",
    "\n",
    "format_axes(ax, title='MAP vs 貝葉斯平均預測', xlabel='x', ylabel='y', legend=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n繪圖完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. IBIS：在線推斷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBIS 用於流式數據處理\n",
    "# 數據分批到達，後驗逐步更新\n",
    "\n",
    "# 生成流式數據\n",
    "N_total = 100\n",
    "X_all = jnp.linspace(-5, 5, N_total)[:, None]\n",
    "f_all = true_function(X_all)\n",
    "key, subkey = jax.random.split(key)\n",
    "Y_all = f_all + noise_std * jax.random.normal(subkey, (N_total,))\n",
    "\n",
    "data = SupervisedData(X_all, Y_all)\n",
    "batch_size = 10\n",
    "n_batches = N_total // batch_size\n",
    "\n",
    "print(f\"總數據點: {N_total}\")\n",
    "print(f\"批次大小: {batch_size}\")\n",
    "print(f\"批次數: {n_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBIS 循環（簡化版本）\n",
    "# 注意：實際實現需要更複雜的粒子更新邏輯\n",
    "print(\"\\nIBIS 示範:\")\n",
    "print(\"（完整實現需要更複雜的粒子管理）\")\n",
    "print(\"\\n關鍵概念：\")\n",
    "print(\"1. 數據分批到達\")\n",
    "print(\"2. 對每個批次更新粒子權重\")\n",
    "print(\"3. 當 ESS 太低時重採樣\")\n",
    "print(\"4. 使用 MCMC 更新保持粒子多樣性\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "在本 notebook 中，我們學習了：\n",
    "\n",
    "1. **後驗不確定性**: SMC 提供完整的後驗分布，而不僅僅是點估計\n",
    "2. **MAP vs 貝葉斯均值**: MAP 估計可能與後驗均值不同\n",
    "3. **超參數相關性**: 聯合分布揭示參數依賴關係\n",
    "4. **不確定性量化**: 標準差量化估計不確定性\n",
    "\n",
    "**何時使用 Annealed SMC：**\n",
    "- 小數據集（高參數不確定性）\n",
    "- 需要魯棒推斷（避免過擬合）\n",
    "- 想要量化超參數不確定性\n",
    "- 模型選擇（通過邊際似然估計）\n",
    "\n",
    "**何時使用 MAP-II：**\n",
    "- 大數據集（後驗集中）\n",
    "- 速度至關重要\n",
    "- 點估計足夠\n",
    "- 生產部署\n",
    "\n",
    "**IBIS 適用場景：**\n",
    "- 數據順序到達（流式）\n",
    "- 數據集太大無法批量處理\n",
    "- 需要實時更新\n",
    "- 監控分布變化\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
