{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: 模型選擇與 RJ-MCMC\n",
    "\n",
    "本 notebook 示範如何使用 Reversible Jump MCMC (RJ-MCMC) 進行自動模型選擇。\n",
    "\n",
    "**學習目標：**\n",
    "- 理解可逆跳躍 MCMC 用於跨維度採樣\n",
    "- 學習如何自動選擇誘導點數量\n",
    "- 應用 RJ-MCMC 到具有挑戰性的回歸問題\n",
    "- 解釋模型複雜度的後驗分布\n",
    "\n",
    "**主要概念：**\n",
    "- **RJ-MCMC**: 在模型空間和參數空間中採樣\n",
    "- **自動模型選擇**: 誘導點數量 M 是推斷的\n",
    "- **貝葉斯模型平均**: 使用後驗分布進行預測\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2026-01-13 09:03:09,688:jax._src.xla_bridge:881: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M4\n",
      "JAX version: 0.8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1768294989.688836 15497219 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1768294989.703742 15497219 service.cc:145] XLA service 0x12b8298d0 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1768294989.703772 15497219 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1768294989.705171 15497219 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1768294989.705185 15497219 mps_client.cc:384] XLA backend will use up to 11452776448 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "os.environ['JAX_PLATFORM_NAME'] = 'cpu'\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plotting_style import COLORS, PALETTES, setup_plot_style, get_figure_size, format_axes\n",
    "setup_plot_style()\n",
    "\n",
    "from infodynamics_jax.core import Phi\n",
    "from infodynamics_jax.gp.kernels.params import KernelParams\n",
    "from infodynamics_jax.gp.kernels.rbf import rbf as rbf_kernel\n",
    "from infodynamics_jax.inference.rj import RJMCMC, RJMCMCCFG\n",
    "from infodynamics_jax.inference.optimisation.vfe import make_vfe_objective\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 理解 RJ-MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RJ-MCMC 在參數 θ 和模型大小 M 的聯合後驗中採樣：\n",
    "\n",
    "$$p(\\theta, M, Z | y) \\propto p(y | \\theta, M, Z) \\cdot p(\\theta) \\cdot p(M) \\cdot p(Z | M)$$\n",
    "\n",
    "其中：\n",
    "- **θ**: 超參數（長度尺度、信號方差、噪聲方差）\n",
    "- **M**: 誘導點數量\n",
    "- **Z**: 誘導點位置（索引）\n",
    "- **VFE**: 變分自由能（Titsias 2009）作為似然近似\n",
    "\n",
    "**移動類型：**\n",
    "1. **Birth**: 添加新的誘導點\n",
    "2. **Death**: 移除誘導點\n",
    "3. **HMC**: 更新超參數（固定 M）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 生成具有挑戰性的數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練數據點數: 1050\n",
      "數據間隙: [0.6, 0.8]\n",
      "真實噪聲標準差: 0.1\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.key(42)\n",
    "\n",
    "# 生成具有間隙的數據\n",
    "N0 = 1200\n",
    "X_raw = jnp.sort(jax.random.uniform(key, (N0, 1), minval=0, maxval=1.5), axis=0)\n",
    "mask = (X_raw < 0.6) | (X_raw > 0.8)\n",
    "X = X_raw[mask].reshape(-1, 1)\n",
    "\n",
    "# 真實函數（具有挑戰性）\n",
    "def true_function(x):\n",
    "    return x * jnp.sin(20 * x) + jnp.sin(4 * x) + (x > 0.5) * 0.5\n",
    "\n",
    "f_true = true_function(X[:, 0])\n",
    "key, subkey = jax.random.split(key)\n",
    "noise_std = 0.1\n",
    "Y = f_true + noise_std * jax.random.normal(subkey, (len(X),))\n",
    "\n",
    "# 測試集\n",
    "X_test = jnp.linspace(0, 1.5, 500)[:, None]\n",
    "f_test = true_function(X_test[:, 0])\n",
    "\n",
    "print(f\"訓練數據點數: {len(X)}\")\n",
    "print(f\"數據間隙: [0.6, 0.8]\")\n",
    "print(f\"真實噪聲標準差: {noise_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 運行 RJ-MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match shape of indexed array in index 0: got (20,), expected [60]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m method = RJMCMC(cfg=rjmcmc_cfg, kernel_fn=rbf_kernel)\n\u001b[32m     35\u001b[39m key, subkey = jax.random.split(key)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m result = \u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43menergy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvfe_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mphi_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mphi_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43menergy_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRJ-MCMC 完成！\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  接受率 (RJ): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.accept_rate_rj\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/infodynamics-jax/examples/../infodynamics_jax/inference/rj/rjmcmc.py:371\u001b[39m, in \u001b[36mRJMCMC.run\u001b[39m\u001b[34m(self, energy, phi_init, key, energy_args, energy_kwargs, init_state)\u001b[39m\n\u001b[32m    369\u001b[39m     state, accepted = \u001b[38;5;28mself\u001b[39m._birth_move(state, X, Y, key)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     state, accepted = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_death_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m accepted:\n\u001b[32m    374\u001b[39m     rj_accepts += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/infodynamics-jax/examples/../infodynamics_jax/inference/rj/rjmcmc.py:192\u001b[39m, in \u001b[36mRJMCMC._death_move\u001b[39m\u001b[34m(self, state, X, Y, key)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Update Z_buf (shift remaining indices)\u001b[39;00m\n\u001b[32m    190\u001b[39m keep_mask = jnp.arange(state.M) != remove_idx\n\u001b[32m    191\u001b[39m new_Z_buf = jnp.concatenate([\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZ_buf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeep_mask\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m    193\u001b[39m     state.Z_buf[state.M:]  \u001b[38;5;66;03m# Keep buffer tail\u001b[39;00m\n\u001b[32m    194\u001b[39m ])\n\u001b[32m    195\u001b[39m new_M = state.M - \u001b[32m1\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# Create new Z with fixed size (M_max, D) - only first M entries are active\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# This ensures phi.Z always has the same shape for jax.lax.cond\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/jax/_src/array.py:372\u001b[39m, in \u001b[36mArrayImpl.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    367\u001b[39m       out = lax.squeeze(out, dimensions=dims)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayImpl(\n\u001b[32m    370\u001b[39m         out.aval, sharding, [out], committed=\u001b[38;5;28;01mFalse\u001b[39;00m, _skip_checks=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/jax/_src/numpy/indexing.py:1056\u001b[39m, in \u001b[36mrewriting_take\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, normalize_indices, out_sharding, strategy)\u001b[39m\n\u001b[32m   1053\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m indexer = \u001b[43mindexer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand_bool_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m dynamic_idx, treedef = tree_flatten(indexer)\n\u001b[32m   1058\u001b[39m internal_gather = partial(\n\u001b[32m   1059\u001b[39m     _gather, treedef=treedef,\n\u001b[32m   1060\u001b[39m     indices_are_sorted=indices_are_sorted, unique_indices=unique_indices,\n\u001b[32m   1061\u001b[39m     mode=mode, fill_value=fill_value, normalize_indices=normalize_indices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/jax/_src/numpy/indexing.py:252\u001b[39m, in \u001b[36mNDIndexer.expand_bool_indices\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    250\u001b[39m expected_shape = [\u001b[38;5;28mself\u001b[39m.shape[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx.consumed_axes]\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(s1 \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m0\u001b[39m, s2) \u001b[38;5;28;01mfor\u001b[39;00m s1, s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(idx_shape, expected_shape)):\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mboolean index did not match shape of indexed array in index\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mposition\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    254\u001b[39m expanded_indices_raw = np.where(np.asarray(idx.index))\n\u001b[32m    255\u001b[39m expanded_indices.extend(ParsedIndex(index=i, typ=IndexType.ARRAY, consumed_axes=(axis,))\n\u001b[32m    256\u001b[39m                         \u001b[38;5;28;01mfor\u001b[39;00m i, axis \u001b[38;5;129;01min\u001b[39;00m safe_zip(expanded_indices_raw, idx.consumed_axes))\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match shape of indexed array in index 0: got (20,), expected [60]"
     ]
    }
   ],
   "source": [
    "# 配置 RJ-MCMC\n",
    "rjmcmc_cfg = RJMCMCCFG(\n",
    "    n_steps=1000,\n",
    "    burn=250,\n",
    "    M_min=5,\n",
    "    M_max=60,\n",
    "    M_init=20,\n",
    "    birth_prob=0.5,\n",
    "    death_mode=\"rank1_last\",  # 或 \"local_rebuild\"\n",
    "    hmc_step_size=1e-2,\n",
    "    hmc_n_leapfrog=8,\n",
    "    hmc_prob=0.3,\n",
    ")\n",
    "\n",
    "# 創建 VFE 目標\n",
    "vfe_objective = make_vfe_objective(kernel_fn=rbf_kernel, residual=\"fitc\")\n",
    "\n",
    "# 初始化 Phi\n",
    "kernel_params = KernelParams(lengthscale=jnp.array(0.1), variance=jnp.array(1.0))\n",
    "M_init = rjmcmc_cfg.M_init\n",
    "key, subkey = jax.random.split(key)\n",
    "Z_indices = jax.random.choice(subkey, len(X), (M_init,), replace=False)\n",
    "Z_init = X[Z_indices]\n",
    "\n",
    "phi_init = Phi(\n",
    "    kernel_params=kernel_params,\n",
    "    Z=Z_init,\n",
    "    likelihood_params={\"noise_var\": jnp.array(0.01)},\n",
    "    jitter=1e-5,\n",
    ")\n",
    "\n",
    "# 運行 RJ-MCMC\n",
    "method = RJMCMC(cfg=rjmcmc_cfg, kernel_fn=rbf_kernel)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "result = method.run(\n",
    "    energy=vfe_objective,\n",
    "    phi_init=phi_init,\n",
    "    key=subkey,\n",
    "    energy_args=(X, Y),\n",
    ")\n",
    "\n",
    "print(\"RJ-MCMC 完成！\")\n",
    "print(f\"  接受率 (RJ): {result.accept_rate_rj:.2%}\")\n",
    "print(f\"  接受率 (HMC): {result.accept_rate_hmc:.2%}\")\n",
    "print(f\"  平均 M: {float(jnp.mean(result.M_trace)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 分析結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取後驗樣本\n",
    "M_trace = np.array(result.M_trace)\n",
    "energy_trace = np.array(result.energy_trace)\n",
    "\n",
    "# 視覺化 M 的後驗分布\n",
    "fig, axes = plt.subplots(2, 2, figsize=get_figure_size('wide', 1.0))\n",
    "\n",
    "# M 軌跡\n",
    "ax = axes[0, 0]\n",
    "ax.plot(M_trace, lw=1, color=COLORS['primary'])\n",
    "ax.axhline(rjmcmc_cfg.M_init, ls=':', lw=1.2, color=COLORS['accent'], \n",
    "          label=f'初始 M={rjmcmc_cfg.M_init}')\n",
    "format_axes(ax, title='模型大小 M 軌跡', xlabel='迭代', ylabel='M', legend=True)\n",
    "\n",
    "# M 的後驗分布\n",
    "ax = axes[0, 1]\n",
    "ax.hist(M_trace, bins=np.arange(M_trace.min()-0.5, M_trace.max()+1.5, 1), \n",
    "       density=True, alpha=0.8, color=COLORS['primary'], edgecolor='black')\n",
    "format_axes(ax, title='M 的後驗分布', xlabel='M', ylabel='密度', legend=False)\n",
    "\n",
    "# 能量軌跡\n",
    "ax = axes[1, 0]\n",
    "ax.plot(energy_trace, lw=1, color=COLORS['secondary'])\n",
    "format_axes(ax, title='能量軌跡', xlabel='迭代', ylabel='能量', legend=False)\n",
    "\n",
    "# M vs 能量\n",
    "ax = axes[1, 1]\n",
    "scatter = ax.scatter(M_trace, energy_trace, c=energy_trace, s=20, alpha=0.6, \n",
    "                    cmap='viridis', edgecolors='none')\n",
    "format_axes(ax, title='M vs 能量', xlabel='M', ylabel='能量', legend=False)\n",
    "plt.colorbar(scatter, ax=ax, label='能量')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "在本 notebook 中，我們學習了：\n",
    "\n",
    "1. **自動複雜度控制**: RJ-MCMC 自動為每個問題選擇適當的 M\n",
    "2. **對不連續性魯棒**: 很好地處理階躍函數和間隙\n",
    "3. **不確定性量化**: 超參數和 M 的完整貝葉斯後驗\n",
    "\n",
    "**配置指南：**\n",
    "\n",
    "**對於平滑函數：**\n",
    "- 較低的 M_max (20-40)\n",
    "- 標準先驗\n",
    "\n",
    "**對於不連續/複雜函數：**\n",
    "- 較高的 M_max (40-80)\n",
    "- 更多樣本 (n_steps > 2000)\n",
    "- 更長的 burn-in\n",
    "\n",
    "**對於更快採樣：**\n",
    "- 使用 `death_mode='rank1_last'`（默認）\n",
    "- 減少 `hmc_n_leapfrog` 用於 theta 更新\n",
    "\n",
    "**對於更好的準確性：**\n",
    "- 使用 `death_mode='local_rebuild'`\n",
    "- 增加 `hmc_n_leapfrog` 並調整 `hmc_step_size`\n",
    "\n",
    "**擴展：**\n",
    "- 多輸出 GP 回歸（獨立輸出）\n",
    "- 不同核函數（Matérn、periodic 等）\n",
    "- 非高斯似然（使用 Laplace 近似）\n",
    "- 流式/在線推斷（增量更新）\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
