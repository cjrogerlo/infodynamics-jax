{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: GP 分類與非共軛似然\n",
    "\n",
    "本 notebook 示範如何使用高斯過程進行分類，處理非共軛似然（Bernoulli）。\n",
    "\n",
    "**學習目標：**\n",
    "- 理解共軛 vs 非共軛似然\n",
    "- 學習使用 Gauss-Hermite 和 Monte Carlo 估計器\n",
    "- 進行二分類和多分類\n",
    "- 視覺化決策邊界和不確定性\n",
    "\n",
    "**關鍵概念：**\n",
    "- **非共軛似然**: Bernoulli、Poisson 等，需要近似方法\n",
    "- **Gauss-Hermite**: 確定性數值積分\n",
    "- **Monte Carlo**: 隨機採樣估計\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['JAX_PLATFORM_NAME'] = 'cpu'\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from plotting_style import COLORS, PALETTES, setup_plot_style, get_figure_size, format_axes, create_custom_colormap\n",
    "setup_plot_style()\n",
    "\n",
    "from infodynamics_jax.core import Phi\n",
    "from infodynamics_jax.gp.kernels.params import KernelParams\n",
    "from infodynamics_jax.gp.kernels.rbf import rbf as rbf_kernel\n",
    "from infodynamics_jax.gp.likelihoods import get as get_likelihood\n",
    "from infodynamics_jax.energy import InertialEnergy, InertialCFG\n",
    "from infodynamics_jax.inference.optimisation import TypeII, TypeIICFG\n",
    "from infodynamics_jax.infodynamics import run, RunCFG\n",
    "from infodynamics_jax.gp.ansatz.state import VariationalState\n",
    "from infodynamics_jax.gp.ansatz.expected import qfi_from_qu_full\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "os.environ['JAX_PLATFORM_NAME'] = 'cpu'\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from utils import COLORS, PALETTES, setup_plot_style, get_figure_size, format_axes, create_custom_colormap\n",
    "setup_plot_style()\n",
    "\n",
    "from infodynamics_jax.core import Phi\n",
    "from infodynamics_jax.gp.kernels.params import KernelParams\n",
    "from infodynamics_jax.gp.kernels.rbf import rbf as rbf_kernel\n",
    "from infodynamics_jax.gp.likelihoods import get as get_likelihood\n",
    "from infodynamics_jax.energy import InertialEnergy, InertialCFG\n",
    "from infodynamics_jax.inference.optimisation import TypeII, TypeIICFG\n",
    "from infodynamics_jax.infodynamics import run, RunCFG\n",
    "from infodynamics_jax.gp.ansatz.state import VariationalState\n",
    "from infodynamics_jax.gp.ansatz.expected import qfi_from_qu_full\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 生成二分類數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(456)\n",
    "N_train = 100\n",
    "\n",
    "# 類別 0: 圍繞 (-2, -2) 的聚類\n",
    "key, subkey = jax.random.split(key)\n",
    "X_class0 = jax.random.normal(subkey, (N_train // 2, 2)) * 0.8 + jnp.array([-2.0, -2.0])\n",
    "\n",
    "# 類別 1: 圍繞 (2, 2) 的聚類\n",
    "key, subkey = jax.random.split(key)\n",
    "X_class1 = jax.random.normal(subkey, (N_train // 2, 2)) * 0.8 + jnp.array([2.0, 2.0])\n",
    "\n",
    "# 合併\n",
    "X_train = jnp.vstack([X_class0, X_class1])\n",
    "Y_train = jnp.concatenate([\n",
    "    jnp.zeros(N_train // 2),\n",
    "    jnp.ones(N_train // 2)\n",
    "])\n",
    "\n",
    "# 打亂\n",
    "key, subkey = jax.random.split(key)\n",
    "perm = jax.random.permutation(subkey, N_train)\n",
    "X_train = X_train[perm]\n",
    "Y_train = Y_train[perm]\n",
    "\n",
    "print(f\"訓練集: {N_train} 個點\")\n",
    "print(f\"類別 0: {jnp.sum(Y_train == 0)} 個點\")\n",
    "print(f\"類別 1: {jnp.sum(Y_train == 1)} 個點\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 訓練 GP 分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 獲取 Bernoulli 似然\n",
    "bernoulli_likelihood = get_likelihood(\"bernoulli\")\n",
    "\n",
    "# 初始化核參數\n",
    "kernel_params = KernelParams(lengthscale=jnp.array(1.0), variance=jnp.array(1.0))\n",
    "\n",
    "# 創建誘導點（網格）\n",
    "M = 20\n",
    "Z_x1 = jnp.linspace(X_train[:, 0].min(), X_train[:, 0].max(), int(jnp.sqrt(M)))\n",
    "Z_x2 = jnp.linspace(X_train[:, 1].min(), X_train[:, 1].max(), int(jnp.sqrt(M)))\n",
    "Z_grid = jnp.stack(jnp.meshgrid(Z_x1, Z_x2), axis=-1).reshape(-1, 2)\n",
    "Z = Z_grid[:M]\n",
    "\n",
    "# 創建 Phi（Bernoulli 沒有噪聲方差）\n",
    "phi_init = Phi(\n",
    "    kernel_params=kernel_params,\n",
    "    Z=Z,\n",
    "    likelihood_params={},  # Bernoulli 沒有額外參數\n",
    "    jitter=1e-5,\n",
    ")\n",
    "\n",
    "# 創建 InertialEnergy（使用 Gauss-Hermite 估計器）\n",
    "inertial_cfg = InertialCFG(\n",
    "    estimator=\"gh\",  # Gauss-Hermite 數值積分\n",
    "    gh_n=20,         # 積分點數\n",
    "    inner_steps=0,   # 無內部優化\n",
    ")\n",
    "\n",
    "inertial_energy = InertialEnergy(\n",
    "    kernel_fn=rbf_kernel,\n",
    "    likelihood=bernoulli_likelihood,\n",
    "    cfg=inertial_cfg,\n",
    ")\n",
    "\n",
    "print(\"InertialEnergy 已創建（Bernoulli 似然 + Gauss-Hermite 估計器）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置並運行 TypeII\n",
    "typeii_cfg = TypeIICFG(steps=150, lr=1e-2, optimizer=\"adam\", jit=True, constrain_params=True)\n",
    "method = TypeII(cfg=typeii_cfg)\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "out = run(\n",
    "    key=subkey,\n",
    "    method=method,\n",
    "    energy=inertial_energy,\n",
    "    phi_init=phi_init,\n",
    "    energy_args=(X_train, Y_train),\n",
    "    cfg=RunCFG(jit=True),\n",
    ")\n",
    "\n",
    "phi_opt = out.result.phi\n",
    "energy_trace = out.result.energy_trace\n",
    "\n",
    "print(\"\\n優化完成！\")\n",
    "print(f\"最終能量: {energy_trace[-1]:.2f}\")\n",
    "print(f\"優化後的超參數:\")\n",
    "print(f\"  長度尺度: {float(phi_opt.kernel_params.lengthscale):.3f}\")\n",
    "print(f\"  方差: {float(phi_opt.kernel_params.variance):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 進行預測並視覺化決策邊界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建預測網格\n",
    "resolution = 100\n",
    "x1_min, x1_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "x2_min, x2_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx1, xx2 = jnp.meshgrid(\n",
    "    jnp.linspace(x1_min, x1_max, resolution),\n",
    "    jnp.linspace(x2_min, x2_max, resolution)\n",
    ")\n",
    "X_grid = jnp.c_[xx1.ravel(), xx2.ravel()]\n",
    "\n",
    "# 計算後驗狀態\n",
    "state = VariationalState.initialise(phi_opt, X_train, Y_train)\n",
    "\n",
    "# 在網格上進行預測\n",
    "mu_grid, var_grid = qfi_from_qu_full(\n",
    "    phi_opt, X_grid, rbf_kernel, state.m_u, state.L_u\n",
    ")\n",
    "\n",
    "mu_grid = mu_grid.squeeze()\n",
    "var_grid = var_grid.squeeze()\n",
    "\n",
    "# 轉換潛在函數為概率: p(y=1) = sigmoid(f)\n",
    "prob_class1 = jax.nn.sigmoid(mu_grid)\n",
    "prob_class1 = prob_class1.reshape(xx1.shape)\n",
    "\n",
    "print(f\"預測完成！\")\n",
    "print(f\"概率範圍: [{prob_class1.min():.3f}, {prob_class1.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化決策邊界\n",
    "fig, axes = plt.subplots(1, 2, figsize=get_figure_size('wide', 0.5))\n",
    "\n",
    "# 圖 1: 決策邊界與類別概率\n",
    "ax = axes[0]\n",
    "prob_cmap = create_custom_colormap('probability')\n",
    "contour = ax.contourf(xx1, xx2, prob_class1, levels=30, cmap=prob_cmap, alpha=0.85, zorder=1)\n",
    "ax.contour(xx1, xx2, prob_class1, levels=[0.5], colors='black', linewidths=3, linestyles='-', zorder=2)\n",
    "\n",
    "ax.scatter(X_train[Y_train == 0, 0], X_train[Y_train == 0, 1], \n",
    "          c=COLORS['class0'], s=70, alpha=0.9, label='類別 0', \n",
    "          edgecolors='white', linewidths=1.5, marker='o', zorder=4)\n",
    "ax.scatter(X_train[Y_train == 1, 0], X_train[Y_train == 1, 1], \n",
    "          c=COLORS['class1'], s=70, alpha=0.9, label='類別 1', \n",
    "          edgecolors='white', linewidths=1.5, marker='s', zorder=4)\n",
    "\n",
    "format_axes(ax, title='決策邊界與類別概率', xlabel='特徵 X₁', ylabel='特徵 X₂', \n",
    "           legend=True, legend_loc='upper right')\n",
    "plt.colorbar(contour, ax=ax, label='P(類別 1)', shrink=0.8)\n",
    "\n",
    "# 圖 2: 預測不確定性\n",
    "ax = axes[1]\n",
    "std_grid = jnp.sqrt(var_grid).reshape(xx1.shape)\n",
    "uncertainty_cmap = create_custom_colormap('uncertainty')\n",
    "contour2 = ax.contourf(xx1, xx2, std_grid, levels=30, cmap=uncertainty_cmap, alpha=0.85, zorder=1)\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c='gray', s=50, alpha=0.6, \n",
    "          edgecolors='white', linewidths=1, zorder=3)\n",
    "\n",
    "format_axes(ax, title='預測不確定性分析', xlabel='特徵 X₁', ylabel='特徵 X₂', legend=False)\n",
    "plt.colorbar(contour2, ax=ax, label='標準差', shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "在本 notebook 中，我們學習了：\n",
    "\n",
    "1. **非共軛似然**: Bernoulli 用於二分類\n",
    "2. **近似方法**: Gauss-Hermite（確定性）vs Monte Carlo（隨機）\n",
    "3. **GP 分類**: 潛在函數 f(x) 由 GP 建模，概率 p(y=1|x) = σ(f(x))\n",
    "4. **不確定性量化**: 自然的不確定性量化\n",
    "\n",
    "**何時使用每個估計器：**\n",
    "\n",
    "| 估計器 | 優點 | 缺點 | 最佳適用 |\n",
    "|--------|------|------|---------|\n",
    "| **Gauss-Hermite** | 確定性、穩定 | 限於 1D 積分 | 標準分類 |\n",
    "| **Monte Carlo** | 可擴展到高維 | 噪聲、收斂較慢 | 多輸出、複雜模型 |\n",
    "\n",
    "**擴展：**\n",
    "- **多類別**: 使用 softmax 似然\n",
    "- **計數數據**: Poisson 或 Negative Binomial\n",
    "- **有序**: 有序類別（評級、嚴重程度）\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
